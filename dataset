
As we are usiong R to analyze the datasets
First of all set the working directories and import the dataset
setwd("D:/RStudio/Bigmart")

 train <- read.csv("Train.csv")
 test <- read.csv("Test.csv")
 
 #check no of columns and rows in the dataset using dim()
 
 dim(train)
#There are 8523 rows and 12 columns in train data set 
dim(train)
[1] 8523   12

dim(test)
#We have 5681 rows and 11 columns in data set. 
[1] 5681   11

Now lets analyze train dataset
#str() gives info about the variables and their types
str(train)
'data.frame': 8523 obs. of 12 variables:
$ Item_Identifier : Factor w/ 1559 levels "DRA12","DRA24",..: 157 9 663 1122 1298 759 697 739 441 991 ...
$ Item_Weight : num 9.3 5.92 17.5 19.2 8.93 ...
$ Item_Fat_Content : Factor w/ 5 levels "LF","low fat",..: 3 5 3 5 3 5 5 3 5 5 ...
$ Item_Visibility : num 0.016 0.0193 0.0168 0 0 ...
$ Item_Type : Factor w/ 16 levels "Baking Goods",..: 5 15 11 7 10 1 14 14 6 6 ...
$ Item_MRP : num 249.8 48.3 141.6 182.1 53.9 ...
$ Outlet_Identifier : Factor w/ 10 levels "OUT010","OUT013",..: 10 4 10 1 2 4 2 6 8 3 ...
$ Outlet_Establishment_Year: int 1999 2009 1999 1998 1987 2009 1987 1985 2002 2007 ...
$ Outlet_Size : Factor w/ 4 levels "","High","Medium",..: 3 3 3 1 2 3 2 3 1 1 ...
$ Outlet_Location_Type : Factor w/ 3 levels "Tier 1","Tier 2",..: 1 3 1 3 3 3 3 3 2 2 ...
$ Outlet_Type : Factor w/ 4 levels "Grocery Store",..: 2 3 2 1 2 3 2 4 2 2 ...
$ Item_Outlet_Sales : num 3735 443 2097 732 995 ...

Next we nweed to check if this dataset is having any missing values
table(is.na(train))
 FALSE   TRUE 
100813   1463 
#this shows that train dataset is having 1463 missing values

#Now lets check the variables in which values are missing

colSums(is.na(train))
  Item_Identifier               Item_Weight 
                        0                      1463 
         Item_Fat_Content           Item_Visibility 
                        0                         0 
                Item_Type                  Item_MRP 
                        0                         0 
        Outlet_Identifier Outlet_Establishment_Year 
                        0                         0 
              Outlet_Size      Outlet_Location_Type 
                        0                         0 
              Outlet_Type         Item_Outlet_Sales 
                        0                         0
                        

Therefore we see that column Item_Weight has 1463 missing values.Lets drwa some more inferences about the dataset

summary(train)

Item_Identifier  Item_Weight     Item_Fat_Content Item_Visibility  
 FDG33  :  10    Min.   : 4.555   LF     : 316     Min.   :0.00000  
 FDW13  :  10    1st Qu.: 8.774   low fat: 112     1st Qu.:0.02699  
 DRE49  :   9    Median :12.600   Low Fat:5089     Median :0.05393  
 DRN47  :   9    Mean   :12.858   reg    : 117     Mean   :0.06613  
 FDD38  :   9    3rd Qu.:16.850   Regular:2889     3rd Qu.:0.09459  
 FDF52  :   9    Max.   :21.350                    Max.   :0.32839  
 (Other):8467    NA's   :1463                                       
                 Item_Type       Item_MRP      Outlet_Identifier
 Fruits and Vegetables:1232   Min.   : 31.29   OUT027 : 935     
 Snack Foods          :1200   1st Qu.: 93.83   OUT013 : 932     
 Household            : 910   Median :143.01   OUT035 : 930     
 Frozen Foods         : 856   Mean   :140.99   OUT046 : 930     
 Dairy                : 682   3rd Qu.:185.64   OUT049 : 930     
 Canned               : 649   Max.   :266.89   OUT045 : 929     
 (Other)              :2994                    (Other):2937     
 Outlet_Establishment_Year Outlet_Size   Outlet_Location_Type
 Min.   :1985                    :2410   Tier 1:2388         
 1st Qu.:1987              High  : 932   Tier 2:2785         
 Median :1999              Medium:2793   Tier 3:3350         
 Mean   :1998              Small :2388                       
 3rd Qu.:2004                                                
 Max.   :2009                                                
                                                             
            Outlet_Type   Item_Outlet_Sales 
 Grocery Store    :1083   Min.   :   33.29  
 Supermarket Type1:5577   1st Qu.:  834.25  
 Supermarket Type2: 928   Median : 1794.33  
 Supermarket Type3: 935   Mean   : 2181.29  
                          3rd Qu.: 3101.30  
                          Max.   :13086.9
  
  #Conclusions drawn from this dataset
  1.Item_Fat_Content has improper  factor levels.
  2.Item_Weight has 1463 missing values.
  3.Outlet_Size has improper factor levels.
  
  #Lets analyze these variables through graphical plots
  From Visualization perspective,I’ll use ggplot2 package.These graphs would help u understand the frequency of 
  variables in the data set.
  
  library("ggplot2")
  #Load ggplot library
  
  ggplot(train, aes(x= Item_Visibility, y = Item_Outlet_Sales)) + geom_point(size = 2.0, color="blue") + xlab("Item Visibility") + ylab("Item Outlet Sales") + ggtitle("Item Visibility vs Item Outlet Sales")
  
  We can see that in Rplot01.jpeg file the  majority of sales has been obtained from products having visibility less than 0.2. This suggests that item_visibility < 2 must be a significant
  factor in determining sales.
  
  #Let’s plot few more interesting graphs and explore hidden meaningful insights.
  
  ggplot(train, aes(Outlet_Identifier, Item_Outlet_Sales)) + geom_bar(stat = "identity", color = "purple")
  +theme(axis.text.x = element_text(angle = 70, vjust = 0.5, color = "black"))  + ggtitle("Outlets vs Total Sales") + theme_bw()
  
  #From the graph pic Rplot02.jpeg we infer that that OUT027 has contributed to majority of sales and OUT19 have 
  the least footfall, thereby contributing to the least outlet sales.
  
   ggplot(train, aes(Item_Type, Item_Outlet_Sales)) + geom_bar( stat = "identity") +theme(axis.text.x = element_text(angle = 70, vjust = 0.5, color = "navy")) 
   + xlab("Item Type") + ylab("Item Outlet Sales")+ggtitle("Item Type vs Sales")
   
   #From the Uploaded Rplot3.jpeg file we infer that Fruits and Vegetables contribute to the highest amount of outlet sales 
   followed by snack foods and household products. 
   
   
  Now lets use a boxplot as th main benefit of box plot is to outlier deviation of corresponding variable.
  
  ggplot(train, aes(Item_Type, Item_MRP)) +geom_boxplot() +ggtitle("Box Plot") + theme(axis.text.x = element_text(angle = 65, vjust = 0.5, color = "red")) + xlab("Item Type") + ylab("Item MRP") + ggtitle("Item Type vs Item Price")

From Rplot4.jpeg file we see that that black line denotes an outlier and  middle line you see in the box is mean value of each item.

Now lets impute the missing values

Previously we saw that Item_Weight has missing values.As Item_Weight is a continuous variable we can impute the missing values with mean/median
of item_weight

First of all we will combine both train and test datasets.But to combine two data frames we have to ensure that they have
equal columns

dim(train)
8523 12

dim(test)
5681 11

#Thios shows that test dataset has one less column.Let’s first add the column. We can give this column any value. 
One approach would be to extract the mean value of sales from train data set and use it as placeholder for test variable Item _Outlet_ Sales. Anyways, let’s make it simple for now.
I’ve taken a value 1. #

#Now combine tha datasets 

test$Item_Outlet_Sales <-  1
combi <- rbind(train, test)

#Now impute the missing values with median.I am using median because it is very robust to outliers.

combi$Item_Weight[is.na(combi$Item_Weight)] <- median(combi$Item_Weight, na.rm = TRUE)
table(is.na(combi$Item_Weight))

Lets proceed with categorical variables.During exploration, we saw there are mis-matched levels in variables 
which needs to be corrected.

> levels(combi$Outlet_Size)[1] <- "Other"
> library(plyr)
> combi$Item_Fat_Content <- revalue(combi$Item_Fat_Content,
+                                   c("LF" = "Low Fat", "reg" = "Regular"))
> combi$Item_Fat_Content <- revalue(combi$Item_Fat_Content, c("low fat" = "Low Fat"))
> table(combi$Item_Fat_Content)

Low Fat Regular 
   9185    5019 
   
   #Using commands above I have renamed levels of Item_Fat Content
   

(Data Manipulstion)The next level of data  exploration :Count of outlet identifiers

> library(dplyr)
> a <- combi%>%
            group_by(Outlet_Identifier)%>%
            tally()

> head(a)
Source: local data frame [6 x 2] Outlet_Identifier n
(fctr)           (int)
1 OUT010         925
2 OUT013         1553
3 OUT017         1543
4 OUT018         1546
5 OUT019         880
6 OUT027         1559

> names(a)[2] <- "Outlet_Count"
> combi <- full_join(a, combi, by = "Outlet_Identifier")


#There are 10 unique outlets in this data. This variable will give us information on count of outlets in the data set. 


Next count of Item identifiers

In the same way we can compute count of item_identifiers

b <- combi%>%
          group_by(Item_Identifier)%>%
          tally()

> names(b)[2] <- "Item_Count"
> head (b)
Item_Identifier   Item_Count
(fctr)            (int)
1 DRA12             9
2 DRA24             10
3 DRA59             10
4 DRB01             8
5 DRB13             9
6 DRB24             8

Count of Outlet years

#This variable represent the information of existence of a particular outlet 

c <- combi%>%
           select(Outlet_Establishment_Year)%>% 
           mutate(Outlet_Year = 2012 - combi$Outlet_Establishment_Year)
 > head(c)
Outlet_Establishment_Year  Outlet_Year
1 1999                       14
2 2009                        4
3 1999                       14
4 1998                       15
5 1987                       26
6 2009                        4

> combi <- full_join(c, combi)
This suggests that outlets established in 1999 were 14 years old in 2012 and so on.

Now lets discover new trends in Item_identifier

Here I’ll use substr(), gsub() function to extract and rename the variables respectively.

> q <- substr(combi$Item_Identifier,1,2)
> q <- gsub("FD","Food",q)
> q <- gsub("DR","Drinks",q)
> q <- gsub("NC","Non-Consumable",q)
> table(q)
   Drinks Food  Non-Consumable 
   1317   10201 2686
   
   after that add his information in our data set with a variable name ‘Item_Type_New.
   combi$Item_Type_New <- q
   
   Label encoding
   
   In our data set, the variable Item_Fat_Content has 2 levels: Low Fat and Regular. 
   So, we’ll encode Low Fat as 0 and Regular as 1. This will help us convert a factor variable in numeric variable.
   
   
   combi$Item_Fat_Content <- ifelse(combi$Item_Fat_Content == "Regular",1,0)
   combi <- dummy.data.frame(combi, names = c('Outlet_Size','Outlet_Location_Type','Outlet_Type', 'Item_Type_New'),  sep='_')
   
   
   library(dummies)
   combi <- dummy.data.frame(combi, names = c('Outlet_Size','Outlet_Location_Type','Outlet_Type', 'Item_Type_New'),  sep='_')
   
   str (combi)
   
   #As you can see, after hot encoding, the original variables are removed automatically from the data set.
   
   
   *********Predictive Analytics**********
   
   Before we start Predictive modelling first divide the datasets
   
   Lets build a regression model using lm()
   
  linearity_model <- lm(Item_Outlet_Sales ~ ., data = new_train)
  summary(linearity_model)

  Output:
  
  Call:
lm(formula = Item_Outlet_Sales ~ ., data = new_train)

Residuals:
    Min      1Q  Median      3Q     Max 
-4285.6  -670.3   -86.8   569.5  7935.0 

Coefficients: (4 not defined because of singularities)
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                      1410.2851    83.9349  16.802  < 2e-16 ***
Item_Weight                        -0.5621     2.9016  -0.194  0.84641    
Item_Visibility                  -294.0695   248.2562  -1.185  0.23623    
Item_MRP                           15.5515     0.1968  79.040  < 2e-16 ***
Outlet_Size_Other                -126.5263    45.3732  -2.789  0.00531 ** 
Outlet_Size_High                  -78.7257    97.5355  -0.807  0.41960    
Outlet_Size_Medium                 97.3377    52.3680   1.859  0.06310 .  
Outlet_Size_Small                       NA         NA      NA       NA    
`Outlet_Location_Type_Tier 1`    -109.5460    82.3110  -1.331  0.18326    
`Outlet_Location_Type_Tier 2`      34.4602    82.3173   0.419  0.67550    
`Outlet_Location_Type_Tier 3`           NA         NA      NA       NA    
`Outlet_Type_Grocery Store`     -3131.8509    92.6325 -33.809  < 2e-16 ***
`Outlet_Type_Supermarket Type1` -1242.9727    97.5312 -12.744  < 2e-16 ***
`Outlet_Type_Supermarket Type2` -1726.6473    52.3330 -32.993  < 2e-16 ***
`Outlet_Type_Supermarket Type3`         NA         NA      NA       NA    
Item_Type_New_Drinks               14.4820    49.0778   0.295  0.76794    
Item_Type_New_Food                 48.5112    31.8249   1.524  0.12747    
`Item_Type_New_Non-Consumable`          NA         NA      NA       NA    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1129 on 8509 degrees of freedom
Multiple R-squared:  0.5629,	Adjusted R-squared:  0.5622 
F-statistic: 842.8 on 13 and 8509 DF,  p-value: < 2.2e-16

Adjusted R² measures the goodness of  a regression model. Higher the R², better is the model. Our R² = 0.5629. It means we really did something  wrong.  Let’s figure it out next time.


   
   
   
   
   
  
   
   


